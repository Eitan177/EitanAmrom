{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# B-allele Plot in a Streamlit App Running in Colab"
      ],
      "metadata": {
        "id": "e7_aMcJ2XJzx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Eitan177/EitanAmrom/blob/main/plot_baf.ipynb)"
      ],
      "metadata": {
        "id": "NQKRoUAjY0N9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `!pip install -q streamlit`: Installs the Streamlit library, essential for creating the interactive web app.\n",
        "- `!pip install psutil`: Installs the psutil library, which provides system and process monitoring capabilities (though not directly used in the current code)."
      ],
      "metadata": {
        "id": "978DuYIQXHL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit\n",
        "!pip install psutil"
      ],
      "metadata": {
        "id": "7mgQpMk7nRYk",
        "outputId": "e315cef5-8798-4606-d7fa-352f6826f6b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (5.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a Streamlit application that visualizes allele frequencies from a variant call format (VCF) file or a similar tabular data file.  Let's break down the code section by section:\n",
        "\n",
        "**2. Streamlit App Setup (`app.py`):**\n",
        "\n",
        "- `st.set_page_config(layout='wide')`: Configures the Streamlit page layout to utilize the entire browser width, enhancing the visualization.\n",
        "- `st.title(...)`: Sets the title of the web app.\n",
        "- File Uploader: `st.file_uploader(...)`:  Creates an interactive file upload widget in the app. Users can upload files (txt, maf, table formats) containing variant data.\n",
        "- Checkboxes and Radio Buttons: `st.checkbox(...)` and `st.radio(...)` create interactive controls to filter and customize the plot:\n",
        "    - `onlysnps`: Filters for SNPs (single nucleotide polymorphisms).\n",
        "    - `usegenomicCoordinate`: Toggles whether to use genomic coordinates or indices for the x-axis.\n",
        "    - `colorselection`: Lets the user choose to color data points by 'Gene' or 'DBSNP' identifier.\n",
        "\n",
        "**3. Data Processing:**\n",
        "\n",
        "- Conditional Data Reading: The code checks the uploaded file type and reads the data accordingly using pandas:\n",
        "    - `.read_table()`: For text or table files (tab-separated).\n",
        "    - `.read_csv()`: For MAF files (tab-separated).\n",
        "    - It handles different file formats and column names gracefully with `try...except` blocks.\n",
        "- Data Cleaning and Transformation:\n",
        "    - Calculates allele frequency ('AF') based on the data available (adjusts the formula depending on the file format).\n",
        "    - Adjusts column names to be consistent across file types\n",
        "    -  Filters data based on the `onlysnps` checkbox.\n",
        "    - Sets up an 'ind' column for the x-axis (index or position).\n",
        "    - Assigns colors based on the `colorselection`.\n",
        "- Plotting with Streamlit:\n",
        "    - `st.columns(...)`: Divides the page into three columns for parallel visualization of different chromosomes.\n",
        "    - Iterates through unique chromosome values (`np.unique(chart_data['CHROM'])`) and plots a scatterplot for each.\n",
        "        - `st.scatter_chart()`: Generates an interactive scatterplot.  x-axis is based on either 'ind' (index or genomic coordinate) and y-axis is 'AF'. The size and color of the points are controlled using other columns ('size', 'color').\n",
        "        - The plots are then positioned in different columns as calculated by the `m % 3` logic.\n",
        "- Display Dataframe:  `st.write(chart_data)` displays the underlying dataframe as a table for further inspection."
      ],
      "metadata": {
        "id": "9-1uY4W8W4JC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import io\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "st.set_page_config(layout='wide')\n",
        "st.title('Plot allele frequency column from vcf file')\n",
        "mvfe=st.file_uploader('Upload master variant file extreme here',type=['txt','maf','table','vcf'])\n",
        "onlysnps=st.checkbox('only SNPs')\n",
        "usegenomicCoordinate=st.checkbox('Use genomic coordinates instead of indices')\n",
        "colorselection=st.radio('color points using:', ['Gene','DBSNP'])\n",
        "\n",
        "def read_vcf(uploaded_file):\n",
        "    # Convert the uploaded file (BytesIO) to a readable format\n",
        "    content = uploaded_file.getvalue().decode(\"utf-8\")\n",
        "\n",
        "    # Filter out metadata lines (starting with ##)\n",
        "    lines = [line for line in content.splitlines() if not line.startswith(\"##\")]\n",
        "\n",
        "    # Read into pandas DataFrame\n",
        "    df = pd.read_csv(io.StringIO(\"\\n\".join(lines)), sep=\"\\t\")\n",
        "    return df\n",
        "\n",
        "def maf_setaf(chart_data):\n",
        "  try:\n",
        "    chart_data['AF']=chart_data['DP4'].str.split(',',expand=True).astype(int).apply(lambda x: x[2:4].sum()/x.sum(),axis=1)\n",
        "  except:\n",
        "    chart_data['AF']=chart_data[['t_alt_count','t_depth']].apply(lambda x: x[0]/x[1],axis=1)\n",
        "  chart_data['POS']=chart_data['Start_Position']\n",
        "  chart_data['GENE']=chart_data['Hugo_Symbol']\n",
        "  chart_data['CHROM']=chart_data['Chromosome']\n",
        "  return chart_data\n",
        "\n",
        "def vcf_setaf(chart_data):\n",
        "  #st.write(chart_data)\n",
        "  rows_to_drop = []\n",
        "  last_column_name = chart_data.columns[-1]\n",
        "  for index, row in chart_data.iterrows():\n",
        "    match = re.search(r'(\\d+),(\\d+):(\\d+),(\\d+)$', row[last_column_name])\n",
        "    if match:\n",
        "      # Extract numbers\n",
        "      num1, num2, num3, num4 = map(int, match.groups())\n",
        "\n",
        "      # Compute conditions\n",
        "      total = num1 + num2 + num3 + num4\n",
        "      condition1 = total > 50\n",
        "      condition2 = num2 >= 10 and num4 >= 10\n",
        "\n",
        "      if condition1 and condition2:\n",
        "          fraction = (num2 + num4) / total\n",
        "          chart_data.at[index, 'AF'] = fraction\n",
        "          chart_data.at[index, 'POS'] = row['POS']\n",
        "          chart_data.at[index, 'GENE'] = \".\"\n",
        "          chart_data.at[index,'dbSNP_RS'] = row['ID']\n",
        "          chart_data.at[index, 'CHROM'] = row['#CHROM']\n",
        "      else:\n",
        "          rows_to_drop.append(index)  # Mark row for removal\n",
        "    else:\n",
        "      rows_to_drop.append(index)  # Remove row if regex doesn't match\n",
        "\n",
        "  # Drop rows that didn't meet conditions\n",
        "  chart_data.drop(rows_to_drop, inplace=True)\n",
        "  chart_data.reset_index(drop=True, inplace=True)  # Reset index after dropping\n",
        "  return chart_data\n",
        "if mvfe != None:\n",
        "    st.write(mvfe.name)\n",
        "    if mvfe.type == \"text/plain\":\n",
        "        st.write('reading text file')\n",
        "        chart_data = pd.read_table(mvfe,sep='\\t')\n",
        "    elif re.findall('table',mvfe.name):\n",
        "        st.write('reading table file')\n",
        "        chart_data = pd.read_table(mvfe,sep='\\t',skiprows=1)\n",
        "        chart_data['AF']=chart_data['allele_frequency']\n",
        "        chart_data['POS']=chart_data['position']\n",
        "        chart_data['GENE']=chart_data['alt_count']\n",
        "        chart_data['CHROM']=chart_data['contig']\n",
        "    elif re.findall('maf',mvfe.name):\n",
        "        st.write('reading maf file')\n",
        "        chart_data = pd.read_csv(mvfe,sep='\\t',skiprows=1)\n",
        "        chart_data=maf_setaf(chart_data)\n",
        "    else:\n",
        "        st.write('reading vcf file')\n",
        "        chart_data=read_vcf(mvfe)\n",
        "        chart_data=vcf_setaf(chart_data)\n",
        "    if onlysnps:\n",
        "        try:\n",
        "            chart_data=chart_data.iloc[np.where(chart_data['rsID'].str.contains('rs'))[0]]\n",
        "        except:\n",
        "             chart_data=chart_data.iloc[np.where(chart_data['dbSNP_RS'].str.contains('rs'))[0]]\n",
        "    chart_data['ind']=  chart_data['POS']\n",
        "    if colorselection=='Gene':\n",
        "        chart_data['gene_v_snp']=[str(y) for y in chart_data['GENE']]\n",
        "    else:\n",
        "        chart_data['gene_v_snp']=[str(y) for y in chart_data['dbSNP_RS']]\n",
        "\n",
        "    # Display a scatterplot chart\n",
        "    cola,colb,colc= st.columns(3)\n",
        "    m=0\n",
        "    for a in np.unique(chart_data['CHROM']):\n",
        "        chrom = chart_data[chart_data['CHROM']==a]\n",
        "        if not usegenomicCoordinate:\n",
        "            chrom['ind']=np.arange(0,chrom.shape[0])\n",
        "        chrom.reset_index(inplace=True)\n",
        "        if m % 3 == 0:\n",
        "            with cola:\n",
        "                st.title(a+ ' x-axis index')\n",
        "                st.scatter_chart(chrom,x='ind', y='AF',size=30,color='gene_v_snp')\n",
        "        elif m % 3 == 1:\n",
        "            with colb:\n",
        "                st.title(a+ ' x-axis index')\n",
        "                st.scatter_chart(chrom,x='ind', y='AF',size=30,color='gene_v_snp')\n",
        "\n",
        "        elif m % 3 == 2:\n",
        "\n",
        "            with colc:\n",
        "                st.title(a+ ' x-axis index')\n",
        "                st.scatter_chart(chrom,x='ind', y='AF',size=30,color='gene_v_snp')\n",
        "        m+=1\n",
        "    st.write(chart_data)"
      ],
      "metadata": {
        "id": "aKX3nAobnS9J",
        "outputId": "921e3442-df38-471c-eb4a-2d3aae1afbef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The command `!wget -q -O - https://loca.lt/mytunnelpassword` downloads the content of the URL `https://loca.lt/mytunnelpassword` and prints it to the standard output without any progress indication. Let's break down the options:\n",
        "\n",
        "* `!wget`: This invokes the `wget` command, a utility for downloading files from the web.  The `!` indicates that this is a shell command being executed within the notebook environment.\n",
        "\n",
        "* `-q`: This option makes `wget` run in quiet mode.  Normally, `wget` would print progress information (percentage downloaded, download speed) to the console.  `-q` suppresses this output.\n",
        "\n",
        "* `-O -`: Specifies the output file for the downloaded content.  Using `-` as the filename redirects the output to the standard output (stdout) of the shell.  In other words, the downloaded content will be displayed directly in the output of the notebook cell.\n",
        "\n",
        "* `https://loca.lt/mytunnelpassword`: This is the URL from which the content is downloaded.  It appears to be retrieving a \"mytunnelpassword\" from a service called `loca.lt`, likely a password or some authorization token needed for a local tunnel."
      ],
      "metadata": {
        "id": "_u5SYuR-Xxlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - https://loca.lt/mytunnelpassword"
      ],
      "metadata": {
        "id": "qjApuFRonTFm",
        "outputId": "b76fcd68-5424-4227-8e9e-a313c0f9437f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.245.28.160"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`!streamlit run app.py &>/content/logs.txt &`**:\n",
        "\n",
        "   - `!streamlit run app.py`: This command runs the Streamlit application defined in the `app.py` file.  Streamlit creates a web server to host the interactive application.\n",
        "   - `&>/content/logs.txt`: This redirects both standard output (stdout) and standard error (stderr) from the `streamlit run` command to a file named `logs.txt` in the `/content/` directory. This is useful for debugging because any messages or errors from the Streamlit server will be captured in this log file instead of cluttering the Colab output.\n",
        "   - `&`: This runs the `streamlit run` command in the background.  Without this, the Colab notebook cell would be blocked until the Streamlit server is manually stopped.  The `&` allows the cell execution to finish, and the Streamlit app continues to run independently.\n",
        "\n",
        "**`!npx localtunnel --port 8501`**:\n",
        "\n",
        "   - `!npx localtunnel`: This uses `npx` (a tool for executing Node packages) to run the `localtunnel` utility. `localtunnel` creates a public URL that forwards traffic to a local port on your machine (in this case, Colab's virtual machine).  This is how you can access the Streamlit app from outside the Colab environment.\n",
        "   - `--port 8501`:  This specifies the local port that `localtunnel` should forward requests to. Streamlit typically runs on port 8501."
      ],
      "metadata": {
        "id": "WQQ20inyYPk0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "yxl7XpzgnPPQ",
        "outputId": "c37a5b58-c80b-4cf8-b84f-06656af7ec06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0Kyour url is: https://ten-dryers-rest.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &\n",
        "!npx localtunnel --port 8501"
      ]
    }
  ]
}